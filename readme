Road extraction from remote sensing images holds significant application value in various aspects of daily life. However, it is still challenging to extract high-quality road labels from remote sensing images due to the interference of objects sharing similar structures with roads in the background, and the occlusion caused by surroundings. In this paper, a road extraction based on the global-local context perception and cross spatial-scale feature interaction is proposed, dubbed as CCNet. First, a local-global context perception module is incorporated to capture the overall features of road, which aims to improve the ability of model to discriminate between roads and similar objects. Then, the cross spatail-scale feature interaction module is designed in the skip connection to effectively fuse the detailed texture features of roads with the precious semantic information to provide rich and accurate road structure features for the decoder. Experiments conducted on public road datasets demonstrate that  CCNet outperforms existing methods in terms of comprehensive metrics such as F1 and Intersection over Union (IoU). The results indicate that CCNet can produce road labels with superior connectivity and quality.
